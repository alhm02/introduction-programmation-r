\chapter{Le S et la régression linéaire}
\index{regression@régression|(}
\label{regression}


Comme tous les grands logiciels statistiques --- et même plusieurs
calculatrices scientifiques --- S-Plus et \textsf{R} comportent des
fonctions pour calculer les coefficients d'une régression simple ou
multiple. Les outils disponibles vont toutefois bien au-delà de ce
calcul relativement simple. Par l'entremise de quelques fonctions
génériques simples à utiliser, il est ainsi possible de générer
différents graphiques relatifs à la régression, de calculer le tableau
ANOVA de celle-ci et d'en extraire les informations principales, de
calculer des prévisions ainsi que des intervalles de confiance. Bref,
l'analyse complète d'un ensemble de données tient en quelques lignes
de code; il suffit de connaître les fonctions à utiliser.

Le but de ce chapitre consiste à présenter les principales fonctions
--- dont la liste se trouve au tableau \ref{tab:regression:fonctions}
--- utiles lors de l'analyse de données et la modélisation par
régression.  Il n'a cependant aucune prétention d'exhaustivité.
Consulter l'aide en ligne de S-Plus ou \textsf{R}, ainsi que
\citet{MASS} pour de plus amples détails.

À noter que l'on souligne les menues différences entre S-Plus et
\textsf{R}, mais que les exemples ont été exécutés en \textsf{R}.

\begin{table}[htbp]
  \centering
  \begin{threeparttable}
    \begin{tabular}{ll}
      \toprule
      \textbf{Phase de l'analyse} & \textbf{Fonctions} \\
      \midrule
      Création et manipulation de \emph{data frames}
        & \fonction{data.frame} \\
        & \fonction{as.data.frame} \\
        & \fonction{read.table} \\
        & \fonction{cbind} \\
        & \fonction{rbind} \\
        & \fonction{names}, \fonction{colnames}\tnote{1} \\
        & \fonction{row.names}, \fonction{rownames}\tnote{1} \\
        & \fonction{attach} \\
        & \fonction{detach} \\
      \midrule
      Modélisation
        & \fonction{lm} \\
        & \fonction{add1}, \fonction{addterm}\tnote{2} \\
        & \fonction{drop1}, \fonction{dropterm}\tnote{2} \\
        & \fonction{step}, \fonction{stepAIC}\tnote{2} \\
      \midrule
      Analyse des résultats et diagnostics
        & \fonction{summary} \\
        & \fonction{anova} \\
        & \fonction{coef}, \fonction{coefficients} \\
        & \fonction{confint}\tnote{1} \\
        & \fonction{residuals} \\
        & \fonction{fitted} \\
        & \fonction{deviance} \\
        & \fonction{df.residual}\tnote{1} \\
      \midrule
      Mise à jour et prévision
        & \fonction{update} \\
        & \fonction{predict} \\
      \midrule
      Graphiques
        & \fonction{plot} \\
        & \fonction{abline} \\
        & \fonction{matplot} \\
        & \fonction{matlines} \\
      \bottomrule
    \end{tabular}
    \begin{tablenotes}
    \item[1] \textsf{R} seulement.
    \item[2] Dans le package \texttt{MASS}\index{package@\texttt{MASS}}.
    \end{tablenotes}
  \end{threeparttable}
  \caption{Principales fonctions S-Plus et \textsf{R} pour la
    régression linéaire}
  \label{tab:regression:fonctions}
\end{table}


\section{Importation de données}
\index{regression@régression!importation de données}
\label{regression:importation}

La modélisation statistique en S --- comme, par exemple, l'analyse de
régression --- repose souvent sur l'utilisation de \emph{data
  frames}\index{data frame} pour le stockage des données. On se
référera à la section \ref{bases:dataframes} pour une présentation
générale de ce type d'objet.

La principale fonction utilisée pour importer des données dans S-Plus
ou \textsf{R} en vue d'une analyse de régression est
\Fonction{read.table}. Celle-ci retourne un \emph{data frame}. Les
arguments de \code{read.table} les plus souvent utilisés sont:
\begin{ttscript}{comment.char}
\item[\code{file}] le nom ou l'URL (\textsf{R} seulement) \R du fichier de
  données à importer;
\item[\code{header}] \texttt{TRUE} si la première ligne du fichier à être lue
  contient les étiquettes des colonnes;
\item[\code{comment.char}] le \R caractère (\texttt{\#} par défaut)
  représentant le début d'un commentaire dans le fichier (\textsf{R}
  seulement);
\item[\code{skip}] le nombre de lignes à sauter au début du fichier
  (principalement utilisé pour sauter des lignes de commentaires dans
  S-Plus).
\end{ttscript}


\section{Formules}
\index{regression@régression!formules}
\label{regression:formules}

Lorsque l'on fait une régression, il faut informer S-Plus ou
\textsf{R} des variables que l'on entend inclure dans celle-ci et de
quelle façon. La convention utilisée dans le langage S est celle dite
des «formules»\Index{formule}. Le tableau \ref{tab:formules} présente
quelques exemples de formulation de modèles linéaires simples en S.

\begin{table}
  \centering
  \begin{tabular}{ll}
    \toprule
    \textbf{Modèle mathématique} & \textbf{Formule S} \\
    \midrule
    $y_i = \alpha + \beta x_i + \varepsilon_i$
      & \verb=y ~ x= \\
      & \verb=y ~ 1 + x= \\
    \midrule
    $y_i = \beta x_i + \varepsilon_i$
      & \verb=y ~ -1 + x= \\
      & \verb=y ~ x - 1= \\
    \midrule
    $y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \varepsilon_i$
      & \verb=y ~ x1 + x2= \\
      & \verb=y ~ x= où \verb=x <- cbind(x1, x2)= \\
    \bottomrule
  \end{tabular}
  \caption{Modèles linéaires simples et leur formulation en S}
  \label{tab:formules}
\end{table}

Pour une utilisation de base des fonctions de régression, la
connaissance les règles suivantes suffit.
\begin{enumerate}
\item Les opérateurs \code{+} et \code{-} prennent une nouvelle
  signification dans les formules: \fonction{+} signifie «inclusion»
  et \fonction{-}, «exclusion».
\item Le terme constant d'une régression est inclus implicitement.
  Pour l'exclure explicitement (régression passant par l'origine), il
  faut donc ajouter un terme \code{-1} du côté droit de la formule.
\item Dans une régression multiple, on peut soit lister toutes les
  variables à inclure du côté droit de la formule, soit ne spécifier
  qu'une matrice contenant ces variables (dans les colonnes).
\end{enumerate}

Consulter les sections 6.2 de \citet{MASS} et 11.1 de \cite{Rintro}
pour plus de détails.


\section{Modélisation des données}
\index{regression@régression!modélisation}
\label{regression:modelisation}

Supposons que l'on souhaite étudier la relation entre la variable
indépendante \code{x1} et la variable dépendante (ou réponse)
\code{y1} du jeu de données \texttt{anscombe}. La première étape de la
modélisation des données en régression linéaire simple consiste
habituellement à représenter celles-ci graphiquement.

La fonction \fonction{plot} est une fonction générique comportant des
méthodes pour un grand nombre de classes d'objets différentes.
Puisqu'une méthode existe pour les objets de classe \classe{formula},
on peut tracer un graphique de \code{y1} en fonction de \code{x1} avec
\begin{Sinput}
> plot(y1 ~ x1, data=anscombe)
\end{Sinput}
ou, si les colonnes du \emph{data frame} \texttt{anscombe} sont visibles,
simplement avec
\begin{Sinput}
> plot(y1 ~ x1)
\end{Sinput}
Le résultat de ces commandes se trouve à la figure \ref{fig:relation}.

\begin{figure}
  \centering
\includegraphics{regression-002}
  \caption{Relation entre \code{y1} et \code{x1} des données
    \texttt{anscombe}}
  \label{fig:relation}
\end{figure}

Le graphique nous montre qu'il est raisonnable de postuler une
relation linéaire entre les éléments de \code{y1} et \code{x1}. On
pose donc le modèle
\begin{displaymath}
  y_i = \beta_0 + \beta_1 x_i + \varepsilon_i,
\end{displaymath}
où $y_i$ et $x_i$, $i = 1, \dots, 11$ sont les éléments des vecteurs
\code{y1} et \code{x1}, respectivement, et $\varepsilon_i$ est le
terme d'erreur.

C'est avec la fonction \Fonction{lm} (pour \emph{linear model}) que
l'on calcule les estimateurs des coefficients de la régression
$\beta_0$ et $\beta_1$. De façon simplifiée, cette fonction prend en
arguments une formule et un \emph{data frame} dans lequel se trouvent
les données relatives aux termes de celle-ci. La fonction \code{lm}
retourne un objet de classe \classe{lm} pour laquelle il existe de
nombreuses méthodes.
\begin{Schunk}
\begin{Sinput}
> (fit <- lm(y1 ~ x1, data = anscombe))
\end{Sinput}
\begin{Soutput}
Call:
lm(formula = y1 ~ x1, data = anscombe)

Coefficients:
(Intercept)           x1  
     3.0001       0.5001  
\end{Soutput}
\begin{Sinput}
> class(fit)
\end{Sinput}
\begin{Soutput}
[1] "lm"
\end{Soutput}
\end{Schunk}


\section{Analyse des résultats}
\label{regression:analyse}

Le résultat de la fonction \fonction{lm} est une liste dont on peut
extraire manuellement les différents éléments (consulter la rubrique
d'aide). Grâce à quelques fonctions génériques disposant d'une méthode
pour les objets de classe \classe{lm}, il est toutefois facile et
intuitif d'extraire les principaux résultats d'une régression:
\begin{enumerate}
\item \fonction{coef} ou \fonction{coefficients} extraient les
  coefficients $\hat{\beta}_0$ et $\hat{\beta}_1$ de la régression;
\item \fonction{fitted} extrait les valeurs ajustées $\hat{y}_i =
  \hat{\beta}_0 + \hat{\beta}_1 x_i$;
\item \fonction{residuals} extrait les résidus $y_i - \hat{y}_i$;
\item \fonction{deviance} retourne la somme des carrés des résidus
  $\mathrm{SSR} = \sum_{i=1}^n (y_i - \hat{y}_i)^2$;
\item \fonction{df.residual} \R extrait le nombre de degrés de liberté
  de la somme des carrés des résidus (\textsf{R} seulement).
\end{enumerate}

La fonction générique \fonction{summary} présente les informations
ci-dessus de manière facile à consulter. Plus précisément, le sommaire
de la régression contient, outre le modèle utilisé et les estimateurs
des coefficients de la régression: les résultats des tests $t$, la
valeur du coefficient de détermination
\begin{displaymath}
  R^2 = 1 - \frac{\sum_{i=1}^n (y_i - \hat{y}_i)^2}{\sum_{i=1}^n
    (y_i - \bar{y})^2}
\end{displaymath}
et, dans \textsf{R} \R seulement, du coefficient de détermination
ajusté
\begin{displaymath}
  R_a^2 = 1 - (1 - R^2) \frac{n - 1}{n - p - 1},
\end{displaymath}
ainsi que le résultat du test $F$ global.

La fonction \Fonction{confint} \R calcule les intervalles de confiance
des paramètres de la régression (\textsf{R} seulement).

D'autre part, le tableau d'analyse de variance (séquentiel, en
régression multiple) est calculé avec la fonction générique
\fonction{anova}.

Pour ajouter la droite de régression au graphique créé au début de
l'analyse, utiliser la fonction \fonction{abline}, qui dispose elle
aussi d'une méthode pour les objets de classe \code{lm}.


\section{Diagnostics}
\index{regression@régression!diagnostics}
\label{regression:diagnostics}

Les statistiques servant à mesurer la qualité d'un modèle de
régression ($R^2$, $R^2$ ajusté, statistiques $t$ et $F$) sont
calculées par les fonctions \fonction{summary} et \fonction{anova}.

La méthode de la fonction \fonction{plot} pour les objets de classe
\classe{lm} produit une série de six graphiques (quatre dans
\textsf{R} avant la version 2.2.0) permettant de juger de la qualité
d'une régression.  Consulter la rubrique d'aide de la fonction
\fonction{plot.lm} pour plus de détails.


\section{Mise à jour des résultats et prévision}
\index{regression@régression!prévision}
\label{regression:prevision}

Il peut arriver que, une fois la modélisation d'un ensemble de données
effectuée, il soit nécessaire d'ajouter ou de modifier une ou
plusieurs données ou variables. Plutôt que de reprendre toute la
modélisation avec la fonction \code{lm}, il peut alors s'avérer plus
simple et élégant d'utiliser la fonction \fonction{update}.
\begin{Schunk}
\begin{Sinput}
> update(fit, ~. + x4)
\end{Sinput}
\begin{Soutput}
Call:
lm(formula = y1 ~ x1 + x4, data = anscombe)

Coefficients:
(Intercept)           x1           x4  
    4.33291      0.45073     -0.09873  
\end{Soutput}
\end{Schunk}

Le calcul de prévisions et d'intervalles de confiance et de prévision
se fait avec la fonction générique \fonction{predict} et sa méthode
pour les objets de classe \code{lm}. Par défaut, \fonction{predict}
calculera les prévisions pour les valeurs $x_i$, $i = 1, \dots, n$.
Par conséquent, le résultat de \fonction{predict} sera le même que
celui de \fonction{fitted}:
\begin{Schunk}
\begin{Sinput}
> all.equal(predict(fit), fitted(fit))
\end{Sinput}
\begin{Soutput}
[1] TRUE
\end{Soutput}
\end{Schunk}
Comme on souhaite généralement prévoir la réponse pour d'autres
valeurs de la variable indépendante, on spécifiera celles-ci par le
biais d'un \emph{data frame} passé à \fonction{predict} avec l'option
\argument{newdata}.

Le calcul des intervalles de confiance et de prévision diffère entre
S-Plus et \textsf{R}. Dans \Splus S-Plus, les intervalles de confiance
en chaque point seront calculés par \fonction{predict} avec l'option
\code{ci.fit = T}\indexargument{ci.fit}, alors que les intervalles de
prévision le sont avec \texttt{pi.fit = T}\indexargument{pi.fit}. Il
est par conséquent possible de calculer en un seul appel à
\fonction{predict} les deux types d'intervalles. Le niveau de
confiance est spécifié avec l'option \argument{conf.level} ($0,95$ par
défaut).

Si un ou plusieurs intervalles de confiance sont calculés, le résultat
de \fonction{predict} est une liste nommée dont les éléments sont
\verb=$fit=, \verb=$ci.fit= et \verb=$pi.fit= (et ce peu importe le
nom de l'objet contenant le modèle linéaire).

Dans \R \textsf{R}, il n'est pas possible de calculer les deux types
d'intervalles en un seul appel à \fonction{predict}. Pour calculer les
intervalles de confiance, on utilisera l'option
\verb!interval="confidence"!\indexargument{interval}, alors que pour
les intervalles de prévision on utilise \verb!interval="prediction"!.
Le niveau de confiance est déterminé avec l'option \argument{level}. Le
résultat est une matrice de trois colonnes dont la première contient
les prévisions et les deux autres les bornes inférieures
(\code{lwr}) et supérieures (\code{upr}) des intervalles de
confiance.

Les limites des intervalles de confiance peuvent être ajoutées au
graphique des données avec les fonctions \fonction{matlines} ou
\fonction{matplot} \R (\textsf{R} seulement). Consulter les rubriques
d'aide et les exemples pour de plus amples détails.

\index{regression@régression|)}


\section{Exemples}
\label{regression:exemples}

\lstinputlisting{regression.R}


\section{Exercices}
\label{regression:exercices}

\begin{exercice}
  Importer dans S-Plus ou \textsf{R} l'ensemble de données
  \texttt{steam.dat} se trouvant dans le site Internet
  \begin{quote}
    \url{http://vgoulet.act.ulaval.ca/pub/data/}
  \end{quote}
  à l'aide de la fonction \fonction{read.table}. Les trois première
  lignes du fichier sont des lignes de commentaires débutant par le
  caractère \code{\#}. La quatrième ligne contient les étiquettes
  des colonnes.
\end{exercice}

\begin{exercice}
  Rendre les colonnes individuelles de l'ensemble de données
  \texttt{steam} visibles dans l'espace de travail.
\end{exercice}

\begin{exercice}
  Faire (même à l'aveuglette) l'analyse de régression de la variable
  \code{Y} en fonction de la variable \code{X7} des données
  \texttt{steam}.
  \begin{enumerate}
  \item Évaluer visuellement le type de relation pouvant exister entre
    \code{Y} et \code{X7}.
  \item Évaluer les coefficients d'une régression linéaire entre
    \code{Y} et \code{X7} et ajouter la droite de régression ainsi
    obtenue au graphique créé en (a).
  \item Répéter la partie (b) en forçant la droite de régression à
    passer par l'origine $(0, 0)$. Quel modèle semble le plus
    approprié?
  \item Le coefficient de détermination $R^2$ mesure la qualité de
    l'ajustement d'une droite de régression aux données. Calculer le
    $R^2$ pour les modèles en (b) et (c).  Obtient-on les mêmes
    résultats que ceux donnés par \fonction{summary}? Semble-t-il y
    avoir une anomalie?
  \item Calculer les prévisions de chaque modèle pour quelques valeurs
    choisies de la variable indépendante.
  \item Calculer les intervalles de confiance et de prévision pour
    tous les points de \code{X7} (bref, ne pas utiliser
    \texttt{newdata}). Ajouter les limites inférieures et supérieures
    des intervalles au graphique créé précédemment. Utiliser des types
    de lignes (option \code{lty}) et des couleurs (option
    \code{col}) différents pour chaque ensemble de limites.
  \end{enumerate}
\end{exercice}

\begin{exercice}
  Répéter l'exercice précédent en ajoutant la variable \code{X5}
  à l'analyse, transformant ainsi le modèle de régression linéaire
  simple en un modèle de régression multiple.
\end{exercice}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "introduction_programmation_S"
%%% End:
